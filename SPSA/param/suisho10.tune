#set file engine\yaneuraou-engine\yaneuraou-search.cpp
#set declaration %%TUNE_DECLARATION%%
#set options %%TUNE_OPTIONS%%
#context correction_value

    return 9536@ * pcv + 8494@ * micv + 10132@ * (wnpcv + bnpcv) + 7156@ * cntcv;

#context update_correction_history_nonPawnWeight // update_correction_history()

    constexpr int nonPawnWeight = 165@;

#add

    // constexpr int nonPawnWeight = 165;

#add %%TUNE_DECLARATION%%

    int nonPawnWeight = @;


#context update_correction_history1 // update_correction_history()

    workerThread.pawnCorrectionHistory[pawn_correction_history_index(pos)][us] << bonus;
    workerThread.minorPieceCorrectionHistory[minor_piece_index(pos)][us] << bonus * 145@ / 128;
    workerThread.nonPawnCorrectionHistory[non_pawn_index<WHITE>(pos)][WHITE][us]
      << bonus * nonPawnWeight / 128;
    workerThread.nonPawnCorrectionHistory[non_pawn_index<BLACK>(pos)][BLACK][us]
      << bonus * nonPawnWeight / 128;

#context update_correction_history2 // update_correction_history()

    if (m.is_ok())
    {
        const Square to = m.to_sq();
        const Piece  pc = pos.piece_on(m.to_sq());
        (*(ss - 2)->continuationCorrectionHistory)[pc][to] << bonus * 137@ / 128;
        (*(ss - 4)->continuationCorrectionHistory)[pc][to] << bonus * 64@ / 128;
    }

#context lowPlyHistory_fill

    // üí° lowPlyHistory„ÅØ„ÄÅË©¶ÂêàÈñãÂßãÊôÇ„Å´1Âõû„Å†„Åë„Åß„ÅØ„Å™„Åè„ÄÅ"go"„ÅÆÂ∫¶„Å´ÂàùÊúüÂåñ„Åó„Åü„Åª„ÅÜ„ÅåÂº∑„ÅÑ„ÄÇ
    lowPlyHistory.fill(97@);


#context aspiration_window

            delta     = 5@ + threadIdx % 8 + std::abs(rootMoves[pvIdx].meanSquaredScore) / 9000@;


#context YaneuraOuWorker_clear1

    mainHistory.fill(68@);
    captureHistory.fill(-689@);
    pawnHistory.fill(-1238@);


#context YaneuraOuWorker_clear2

	for (bool inCheck : {false, true})
        for (StatsType c : {NoCaptures, Captures})
            for (auto& to : continuationHistory[inCheck][c])
                for (auto& h : to)
                    h.fill(-529@);

#context YaneuraOuWorker_clear3

	// reductions table„ÅÆÂàùÊúüÂåñ(„Åì„Çå„ÅØWorker„Åî„Å®„ÅåÊåÅ„Å§„Çà„ÅÜ„Å´Â§âÊõ¥„Åï„Çå„Åü)
    for (size_t i = 1; i < reductions.size(); ++i)
        reductions[i] = int(2809@ / 128.0 * std::log(i));

#context Search_tt_lookup1 // search() Step 4.

            if (!ttCapture)
                update_quiet_histories(pos, ss, *this, ttData.move,
                                       std::min(130@ * depth - 71@, 1043@));

#context Search_tt_lookup2

			if (prevSq != SQ_NONE && (ss - 1)->moveCount <= 4 && !priorCapture)
                update_continuation_histories(ss - 1, pos.piece_on(prevSq), prevSq, -2142@);

#context Search_static_evaluation_1a // search Step 6.

        int evalDiff = std::clamp(-int((ss - 1)->staticEval + ss->staticEval), -200@, 156@) + 58@;
        mainHistory[~us][((ss - 1)->currentMove).from_to()] << evalDiff * 9@;

#context Search_static_evaluation_2a

        if (!ttHit && type_of(pos.piece_on(prevSq)) != PAWN
            && ((ss - 1)->currentMove).type_of() != PROMOTION)
            pawnHistory[pawn_history_index(pos)][pos.piece_on(prevSq)][prevSq] << evalDiff * 14@;

#context Search_static_evaluation3

    if (priorReduction >= 2 && depth >= 2 && ss->staticEval + (ss - 1)->staticEval > 173@)
        depth--;

#context Search_razoring // search() Step 7.

    if (!PvNode && eval < alpha - 514@ - 294@ * depth * depth)
        return qsearch<NonPV>(pos, ss, alpha, beta);

#context Search_futility_1 // Search step 8.

		auto futility_margin = [&](Depth d) {
            Value futilityMult = 91@ - 21@ * !ss->ttHit;

            return futilityMult * d                                //
                 - 2094 * improving * futilityMult / 1024          //
                 - 1324 * opponentWorsening * futilityMult / 4096  //
                 + std::abs(correctionValue) / 158105@;
        };

#context Search_nullmove // Search step 9.

    if (cutNode && ss->staticEval >= beta - 18@ * depth + 390@ && !excludedMove

#context Search_Probcut // Search step 11.

    probCutBeta = beta + 224@ - 64@ * improving;

#context Search_small_Probcut // search() Step 12.

    probCutBeta = beta + 418@;

#context Search_decrease_reduction_for_tt_pv // search() Step 13.

        if (ss->ttPv)
            r += 946@;

#context Search_futility_value // search() Step 14.

        Value futilityValue = ss->staticEval + 231@ + 211@ * lmrDepth
                            + PieceValue[capturedPiece] + 130@ * captHist / 1024;

#context Search_Continuation_history_based_pruning1 // search() Step 14.

        if (history < -4312@ * depth)
            continue;

        history += 76@ * mainHistory[us][move.from_to()] / 32;

        // (*Scaler): Generally, a lower divisor scales well
        lmrDepth += history / 3220@;

#context Search_Continuation_history_based_pruning2

        Value futilityValue = ss->staticEval + 47 + 171 * !bestMove + 134@ * lmrDepth
                            + 90@ * (ss->staticEval > alpha);

#context Search_Continuation_history_based_pruning3 

        if (!pos.see_ge(move, -27@ * lmrDepth * lmrDepth))
            continue;

#context Search_Extensions1 // Step 15.

            Value singularBeta  = ttData.value - (56@ + 81@ * (ss->ttPv && !PvNode)) * depth / 60@;
            Depth singularDepth = newDepth / 2;

#context Search_Extensions2

                int corrValAdj   = std::abs(correctionValue) / 229958@;

#context Search_Extensions3

                int doubleMargin = -4@ + 198@ * PvNode - 212@ * !ttCapture - corrValAdj
                                 - 921@ * ttMoveHistory / 127649 - (ss->ply > rootDepth) * 45@;

#context Search_Extensions4

                int tripleMargin = 76@ + 308@ * PvNode - 250@ * !ttCapture + 92@ * ss->ttPv - corrValAdj
                                 - (ss->ply * 2 > rootDepth * 3) * 52@;


#context Search_Decrease_reduction_for_PvNodes_1 // search() Step 16.

		if (ss->ttPv)
            r -= 2618@ + PvNode * 991@ + (ttData.value > alpha) * 903@
               + (ttData.depth >= depth) * (978@ + cutNode * 1051@);

#context Search_Decrease_reduction_for_PvNodes_2

        r += 843@;  // Base reduction offset to compensate for other tweaks

#context Search_Decrease_reduction_for_PvNodes_3

		r -= moveCount * 66@;
        r -= std::abs(correctionValue) / 30450@;

#context Search_Decrease_reduction_for_PvNodes_4

        if (cutNode)
            r += 3094@ + 1056@ * !ttData.move;

#context Search_Decrease_reduction_for_PvNodes_5

        if (ttCapture)
            r += 1415@;

#context Search_Decrease_reduction_for_PvNodes_6

        if ((ss + 1)->cutoffCnt > 2)
            r += 1051@ + allNode * 814@;


#context Search_Decrease_reduction_for_PvNodes_7

        if (move == ttData.move)
            r -= 2018@;

#context Search_Decrease_reduction_for_PvNodes_8

        if (capture)
            ss->statScore = 803@ * int(PieceValue[pos.captured_piece()]) / 128
                          + captureHistory[movedPiece][move.to_sq()][type_of(pos.captured_piece())];

#context Search_Decrease_reduction_for_PvNodes_9

        r -= ss->statScore * 794@ / 8192;

#context Search_Post_LMR_continuation_history_updates // search() Step 17.

        update_continuation_histories(ss, movedPiece, move.to_sq(), 1365@);

#context Search_Full_depth_search_threshold_1a // Step 18.

            if (!ttData.move)
                r += 1118@;

#context Search_Full_depth_search_threshold_2b

            // Note that if expected reduction is high, we reduce search depth here
            // ÊúüÂæÖ„Åï„Çå„ÇãÂâäÊ∏õ„ÅåÂ§ß„Åç„ÅÑÂ†¥Âêà„ÄÅ„Åì„Åì„ÅßÊé¢Á¥¢Ê∑±„Åï„Çí1Ê∏õ„Çâ„Åô„Åì„Å®„Å´Ê≥®ÊÑè„Åó„Å¶„Åè„Å†„Åï„ÅÑ„ÄÇ
			value = -search<NonPV>(pos, ss + 1, -(alpha + 1), -alpha,
                                   newDepth - (r > 3212@) - (r > 4784@ && newDepth > 2), !cutNode);

#context Search_ttMoveHistoryBonus // search() Step 21.

        if (!PvNode)
            ttMoveHistory << (bestMove == ttData.move ? 809@ : -865@);

#context Search_standPat // qsearch() Step 4.

		futilityBase = ss->staticEval + 352@;

#context YaneuraOuWorker_reduction

Depth Search::YaneuraOuWorker::reduction(bool i, Depth d, int mn, int delta) const {
    int reductionScale = reductions[d] * reductions[mn];
    return reductionScale - delta * 757@ / rootDelta + !i * reductionScale * 218@ / 512 + 1200@;

}

#context update_all_stats_1c // update_all_stats()

	int bonus = std::min(121@ * depth - 77@, 1633) + 375@ * (bestMove == ttMove);
	int malus = std::min(825@ * depth - 196@, 2159) - 16@ * moveCount;


#context conthist_bonuses // update_all_stats()

    static constexpr std::array<ConthistBonus, 6> conthist_bonuses = {
      {{1, 1157@}, {2, 648@}, {3, 288@}, {4, 576@}, {5, 140@}, {6, 441@}}};

#add

    // static constexpr std::array<ConthistBonus, 6> conthist_bonuses = { ... };

#add %%TUNE_DECLARATION%%

    std::array<ConthistBonus, 6> conthist_bonuses = {
        {{1, 0 }, {2, 0 }, {3, 0 }, {4, 0 }, {5, 0 }, {6, 0 }}};

#add %%TUNE_ISREADY%%

    {
        int t[6] = {@,@,@,@,@,@};
        for (size_t i = 0; i < conthist_bonuses.size(); ++i)
            conthist_bonuses[i].weight = t[i];
    }

#context update_quiet_histories_1a // update_quiet_histories()

    if (ss->ply < LOW_PLY_HISTORY_SIZE)
        workerThread.lowPlyHistory[ss->ply][move.from_to()] << bonus * 761@ / 1024;

    update_continuation_histories(ss, pos.moved_piece(move), move.to_sq(), bonus * 955@ / 1024);

#context update_quiet_histories_2b // update_quiet_histories()

    int pIndex = pawn_history_index(pos);

    workerThread.pawnHistory[pIndex][pos.moved_piece(move)][move.to_sq()]
      << bonus * (bonus > 0 ? 850@ : 550@) / 1024;
